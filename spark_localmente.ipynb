{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Para executar o Apache Spark localmente, você pode usar o modo \"local\". Esse modo é ideal para desenvolvimento, testes e aprendizado, pois não requer configuração de um cluster. Aqui está um guia passo a passo para configurar e executar o Spark localmente:"
      ],
      "metadata": {
        "id": "1AXhd3aQY4ie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Instalar o Java Development Kit (JDK)\n",
        "\n",
        "O Spark requer o JDK instalado. Se ainda não o fez, instale o OpenJDK:"
      ],
      "metadata": {
        "id": "P8avEn4iZKxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt update\n",
        "sudo apt install openjdk-11-jdk"
      ],
      "metadata": {
        "id": "6OkUZe5IY670"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifique a instalação:"
      ],
      "metadata": {
        "id": "PonXXVUDZS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "java -version"
      ],
      "metadata": {
        "id": "Scy2uJIGZWKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Baixar e Configurar o Apache Spark\n",
        "\n",
        "Baixe o Apache Spark do site oficial. Escolha a versão pré-construída para Hadoop.\n",
        "\n",
        "No terminal, use wget para baixar:"
      ],
      "metadata": {
        "id": "IoC0kHcIZYgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wget https://www.apache.org/dyn/closer.lua/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "V6MaavBdZc6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraia o arquivo baixado:"
      ],
      "metadata": {
        "id": "M735fiNCaUQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tar -xzf spark-3.3.5-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "S8XOj9g4aYaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mova o diretório extraído para um local apropriado, como /opt/spark:"
      ],
      "metadata": {
        "id": "LjS4C6hVafLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo mv spark-3.3.5-bin-hadoop3 /opt/spark"
      ],
      "metadata": {
        "id": "uvwPOr6Aakgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Configurar Variáveis de Ambiente\n",
        "\n",
        "Adicione as variáveis de ambiente ao seu .bashrc ou .zshrc:\n",
        "\n"
      ],
      "metadata": {
        "id": "EtXNuv9Jarpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "echo 'export SPARK_HOME=/opt/spark' >> ~/.bashrc\n",
        "echo 'export PATH=$PATH:$SPARK_HOME/bin' >> ~/.bashrc\n",
        "echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64' >> ~/.bashrc\n",
        "echo 'export PATH=$PATH:$JAVA_HOME/bin' >> ~/.bashrc"
      ],
      "metadata": {
        "id": "JGWLzN1pas99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "source ~/.bashrc"
      ],
      "metadata": {
        "id": "-FddDpkba4mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Executar o Spark no Modo Local\n",
        "\n",
        "O Spark pode ser executado localmente usando o comando spark-shell (para Scala) ou pyspark (para Python). Aqui estão as instruções para ambos:"
      ],
      "metadata": {
        "id": "T3yl-x4ka76r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando pyspark (Python)\n",
        "\n",
        "Inicie o shell do PySpark:"
      ],
      "metadata": {
        "id": "fqp_9lgCbEs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$SPARK_HOME/bin/pyspark --master local[*]"
      ],
      "metadata": {
        "id": "fmU-KsZrbBfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    O parâmetro --master local[*] define o modo local.\n",
        "\n",
        "    Você verá um prompt interativo do PySpark (Python)."
      ],
      "metadata": {
        "id": "VEJf9UZ8bK_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Executar um Script Python com spark-submit\n",
        "\n",
        "Se você quiser executar um script Python localmente (através do Jupyter Notebook por exemplo), use o comando spark-submit:\n",
        "\n",
        "    Crie um arquivo Python, por exemplo, exemplo.py:"
      ],
      "metadata": {
        "id": "Ci9w7G-KbacL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Exemplo Local\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data = [1, 2, 3, 4, 5]\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "print(rdd.collect())"
      ],
      "metadata": {
        "id": "sG2gDxqcbnF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Acessar a Interface do Spark UI\n",
        "\n",
        "Quando você executa o Spark localmente, ele inicia uma interface web para monitoramento. Acesse-a no navegador:\n",
        "\n",
        "Aqui você pode ver informações sobre jobs, estágios, tarefas e uso de recursos."
      ],
      "metadata": {
        "id": "f3qR64A1byCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "http://localhost:4040"
      ],
      "metadata": {
        "id": "hUzQCjOzbz0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}